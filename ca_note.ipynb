{
  "metadata": {
    "name": "Covid Analysis",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n\nval url \u003d \"https://s3.us-east-2.amazonaws.com/covidanalysis/Data_setP2/covid_19_data.csv\"\n\nimport org.apache.spark.SparkFiles\nspark.sparkContext.addFile(url) \nval df1 \u003d spark.read.format(\"csv\")\n  .option(\"inferSchema\", \"true\")\n  .option(\"header\", \"true\")\n  .load(\"file://\"+SparkFiles.get(\"covid_19_data.csv\"))\n  \nval df2 \u003d df1.drop(\"SNo\", \"Last Update\")\n\nval df3 \u003d df2.select(\"Country/Region\", \"Confirmed\")\n\nval df4 \u003d df3.createOrReplaceTempView(\"country\")"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n\nval url \u003d \"https://s3.us-east-2.amazonaws.com/covidanalysis/Data_setP2/US.csv\"\n\nimport org.apache.spark.SparkFiles\nspark.sparkContext.addFile(url) \nval df1 \u003d spark.read.format(\"csv\")\n  .option(\"inferSchema\", \"true\")\n  .option(\"header\", \"true\")\n  .load(\"file://\"+SparkFiles.get(\"US.csv\"))\n  \nval df2 \u003d df1.select(\"date\", \"new_confirmed\", \"new_deceased\", \"new_tested\", \"cumulative_confirmed\", \"cumulative_deceased\", \"cumulative_tested\",\n                        \"new_hospitalized_patients\", \"cumulative_hospitalized_patients\", \"current_hospitalized_patients\", \"new_intensive_care_patients\", \"current_intensive_care_patients\")\n\nval df3 \u003d df2.createOrReplaceTempView(\"us\")"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n-- world total (when? these are in the thousands)\n\nselect `Country/Region`, count(1) as count from country group by `Country/Region`"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n-- newly confirmed US by date\n\nselect `date`, first(`new_confirmed`) as `newly confirmed` from us group by `date` order by `date`"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n-- newly deceased US by date\n\nselect `date`, first(`new_deceased`) as `newly deceased` from us group by `date` order by `date`"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n-- new test results US by date\n\nselect `date`, first(`new_tested`) as `new test results` from us group by `date` order by `date`"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n-- cumulative confirmed cases US by date\n\nselect `date`, first(`cumulative_confirmed`) as `cumulative confirmed cases` from us group by `date` order by `date`"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n-- cumulative deceased cases US by date\n\nselect `date`, first(`cumulative_deceased`) as `cumulative deceased cases` from us group by `date` order by `date`"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n-- cumulative tests US by date\n\nselect `date`, first(`cumulative_tested`) as `cumulative tests` from us group by `date` order by `date`"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n-- newly hospitalized US by date\n\nselect `date`, first(`new_hospitalized_patients`) as `newly hospitalized` from us group by `date` order by `date`"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n-- cumulative hospitalized US by date\n\nselect `date`, first(`cumulative_hospitalized_patients`) as `total hospitalized` from us group by `date` order by `date`"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n-- currently hospitalized US by date\n\nselect `date`, first(`current_hospitalized_patients`) as `currently hospitalized` from us group by `date` order by `date`"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n-- new intensive care patients US by date\n\nselect `date`, first(`new_intensive_care_patients`) as `new IC patients` from us group by `date` order by `date`"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n-- current intensive care patients US by date\n\nselect `date`, first(`current_intensive_care_patients`) as `current IC patients` from us group by `date` order by `date`"
    }
  ]
}