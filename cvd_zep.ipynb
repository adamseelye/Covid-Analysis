{
  "metadata": {
    "name": "Covid Analysis",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh \n\necho \"%html \u003ch3\u003e\u003cb\u003eThank you for visiting today.\u003c/b\u003e\u003c/h3\u003e\"\necho \"%html \u003cbr\u003e\"\necho \"%html \u003ch4\u003eWe use the publicly available data that Google has provided \u003ca href\u003d\u0027https://health.google.com/covid-19/open-data/raw-data\u0027\u003ehere\u003c/a\u003e to analyze certain statics related to the COVID pandemic.\u003c/h4\u003e\"\necho \"%html \u003ch4\u003eEach query is an analysis of data gathered in the US; data are aggregated by Google and come from sources such as the CDC and various hospitals in the United States.\u003c/h4\u003e\"\necho \"%html \u003ch4\u003eThe data has been loaded into an AWS S3 bucket and then manipulated using Spark to be displayed on this page. We may then attempt to infer from the trends a story or narrative.\u003c/h4\u003e\"\necho \"%html \u003ch5\u003eAuthors:\u003c/h5\u003e\"\necho \"%html \u003cul\u003e\u003cli\u003e\u003cb\u003eAdam Seelye\u003c/b\u003e\u003c/li\u003e\u003cli\u003e\u003cb\u003eRoman Davis\u003c/b\u003e\u003c/li\u003e\u003cli\u003e\u003cb\u003eWalter Peña\u003c/b\u003e\u003c/li\u003e\u003cli\u003e\u003cb\u003eSevin Hawkins\u003c/b\u003e\u003c/li\u003e\u003c/ul\u003e\" "
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n\nval url \u003d \"https://s3.us-east-2.amazonaws.com/covidanalysis/Data_setP2/US.csv\"\n\nimport org.apache.spark.SparkFiles\nspark.sparkContext.addFile(url)\nval df1 \u003d spark.read.format(\"csv\")\n  .option(\"inferSchema\", \"true\")\n    .option(\"header\", \"true\")\n      .load(\"file://\"+SparkFiles.get(\"US.csv\"))\n\n        val df2 \u003d df1.select(\"date\", \"new_confirmed\", \"new_deceased\", \"new_tested\", \"cumulative_confirmed\", \"cumulative_deceased\", \"cumulative_tested\",\n                                \"new_hospitalized_patients\", \"cumulative_hospitalized_patients\", \"current_hospitalized_patients\", \"new_intensive_care_patients\", \"current_intensive_care_patients\", \"cumulative_persons_vaccinated\")\n\n                                val df3 \u003d df2.createOrReplaceTempView(\"us\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n-- newly confirmed US by date\n\nselect `date`, first(`new_confirmed`) as `Newly Confirmed` from us group by `date` order by `date`"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n-- newly deceased US by date\n\nselect `date`, first(`new_deceased`) as `New Deceased` from us group by `date` order by `date`"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n-- new test results US by date\n\nselect `date`, first(`new_tested`) as `New Tests` from us group by `date` order by `date`"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n-- cumulative confirmed cases US by date\n\nselect `date`, first(`cumulative_confirmed`) as `Total COVID Cases` from us group by `date` order by `date`"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n-- cumulative deceased cases US by date\n\nselect `date`, first(`cumulative_deceased`) as `Total COVID Deceased` from us group by `date` order by `date`"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n-- cumulative tests US by date\n\nselect `date`, first(`cumulative_tested`) as `Total Tests` from us group by `date` order by `date`"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n-- newly hospitalized US by date\n\nselect `date`, first(`new_hospitalized_patients`) as `New COVID Patients` from us group by `date` order by `date`"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n-- currently hospitalized US by date\n\nselect `date`, first(`current_hospitalized_patients`) as `Current Patients` from us group by `date` order by `date`"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n-- cumulative hospitalized US by date\n\nselect `date`, first(`cumulative_hospitalized_patients`) as `Total COVID Patients` from us group by `date` order by `date`"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n-- new intensive care patients US by date\n\nselect `date`, first(`new_intensive_care_patients`) as `New IC Patients` from us group by `date` order by `date`"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n-- current intensive care patients US by date\n\nselect `date`, first(`current_intensive_care_patients`) as `Current IC Patients` from us group by `date` order by `date`"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n-- cumulative vaccinated US by date\n\nselect `date`, first(`cumulative_persons_vaccinated`) as `Total Vaccinated` from us group by `date` order by `date`"
    }
  ]
}